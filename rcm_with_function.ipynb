{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59601, 481)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.csgraph import reverse_cuthill_mckee\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.sparse as sps\n",
    "from random import randint\n",
    "import operator\n",
    "#df = pd.read_csv('Data/online_retail_transaction.csv',header=None,index_col=None)\n",
    "df = pd.read_csv('Dataset Paper/dataBMS1_transiction.csv',header=None,index_col=None)\n",
    "df.shape # dimensione originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_band_matrix(original_dataset=None, dim_finale=1000, nome_file_item=None, num_sensibile=1):\n",
    "    \"\"\"\n",
    "        Compute band_matrix , permutazione casuale di righe e colonne\n",
    "        estrapola a caso item_sensibili\n",
    "    \"\"\"\n",
    "    if original_dataset is not None and len(original_dataset) >= dim_finale and len(original_dataset.columns) >= dim_finale:\n",
    "        # leggo nomi items\n",
    "        file = open(nome_file_item, \"r\")\n",
    "        items = file.read().splitlines()\n",
    "        # permuto righe e colonne del df inizale e prendo le prime :dim_finale\n",
    "        np.random.seed(seed=13)\n",
    "        random_column = np.random.permutation(original_dataset.shape[1])[:dim_finale]\n",
    "        random_row = np.random.permutation(original_dataset.shape[0])[:dim_finale]\n",
    "        # recupero gli item selezionati nel relativo ordine == colonne\n",
    "        items_reordered = [items[i] for i in random_column]\n",
    "        # df selezionato e square\n",
    "        \n",
    "        # eliminare le righe nulle a priori\n",
    "        df_square = df.iloc[random_row][random_column];\n",
    "        # eliminare solo se items sensibili nulli\n",
    "        \n",
    "        # selezioni gli utlimi num_sensibili come item sensibili\n",
    "        # check se esiste almeno un item sensibile\n",
    "\n",
    "    \n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "        \n",
    "        # check che le colonne sensibili non siano nulle\n",
    "        lista_sensibili = df_square.columns[-num_sensibile:]\n",
    "        # plot matrice sparsa iniziale\n",
    "        # plt\n",
    "        ax1.spy(df_square, marker='.', markersize='1')\n",
    "        #ax1.show()\n",
    "\n",
    "        # applicazione algoritmo RCM\n",
    "        sparse = csr_matrix(df_square)\n",
    "        order = reverse_cuthill_mckee(sparse)\n",
    "\n",
    "        # solo se add gli 0\n",
    "        # riordino i dati sensibili\n",
    "        # df_sensibili = df_sensibili.iloc[order]\n",
    "\n",
    "        # ora devo prendere gli item selzionati prima e riordinarli ancora\n",
    "        # secondo quello scritto in order quindi\n",
    "        items_final = [items_reordered[i] for i in order]\n",
    "        column_reordered = [df_square.columns[i] for i in order]\n",
    "        items_final = dict(zip(column_reordered,items_final))\n",
    "\n",
    "        # df bandizzato\n",
    "        df_square_band = df_square.iloc[order][column_reordered]\n",
    "        # plotto\n",
    "        ax2.spy(df_square_band, marker='.', markersize='1')\n",
    "        #ax2.show()\n",
    "        plt.show()\n",
    "        # banda dataframe inizale\n",
    "        [i, j] = np.where(df_square == 1)\n",
    "        bw = max(i-j) + 1\n",
    "        print(\"Bandwidth first RCM\", bw)\n",
    "\n",
    "        # banda dataframe dopo RCM\n",
    "        [i, j] = np.where(df_square_band == 1)\n",
    "        bw = max(i-j) + 1\n",
    "        print(\"Bandwidth after RCM\", bw)\n",
    "        return df_square_band, items_final, lista_sensibili\n",
    "    \n",
    "    elif original_dataset is not None and len(original_dataset) >= dim_finale:\n",
    "        # devo essere sicuro di avere il numero di righe giusto\n",
    "        # allora devo squadrarlo con la dimensione finale definita dall'utente\n",
    "        file = open(nome_file_item, \"r\")\n",
    "        items = file.read().splitlines()\n",
    "        columns = original_dataset.columns\n",
    "        zero_data_to_add = np.zeros(shape=(len(original_dataset),len(original_dataset)-len(columns)))\n",
    "        # aggiungo li zero con la dimensione finale relativa\n",
    "        #zero_data_to_add.shape\n",
    "        columns_to_add = [\"temp\"+str(x) for x in range(0,len(df_ridotto)-len(columns))]\n",
    "        #columns_to_add\n",
    "        df_to_add = pd.DataFrame(zero_data_to_add, columns=columns_to_add,index=original_dataset.index,dtype='uint8')\n",
    "        #df_to_add\n",
    "        # creo il dataset completo aggiungendo tutti gli zeri che mancano\n",
    "        original_dataset = pd.concat([original_dataset, df_to_add], axis=1)\n",
    "        # permuto righe e colonne del df inizale e prendo le prime :dim_finale\n",
    "        np.random.seed(seed=13)\n",
    "        random_column = np.random.permutation(original_dataset.shape[1])\n",
    "        random_row = np.random.permutation(original_dataset.shape[0])[:dim_finale]\n",
    "        # recupero gli item selezionati nel relativo ordine == colonne\n",
    "        items_reordered = [items[i] for i in random_column]\n",
    "        # df selezionato e square\n",
    "        \n",
    "        # eliminare le righe nulle a priori\n",
    "        df_square = df.iloc[random_row][random_column];\n",
    "        # eliminare solo se items sensibili nulli\n",
    "        \n",
    "        \n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "        \n",
    "        # check che le colonne sensibili non siano nulle\n",
    "        lista_sensibili = df_square.columns[-num_sensibile:]\n",
    "        # plot matrice sparsa iniziale\n",
    "        # plt\n",
    "        ax1.spy(df_square, marker='.', markersize='1')\n",
    "        #ax1.show()\n",
    "\n",
    "        # applicazione algoritmo RCM\n",
    "        sparse = csr_matrix(df_square)\n",
    "        order = reverse_cuthill_mckee(sparse)\n",
    "\n",
    "        # solo se add gli 0\n",
    "        # riordino i dati sensibili\n",
    "        # df_sensibili = df_sensibili.iloc[order]\n",
    "\n",
    "        # ora devo prendere gli item selzionati prima e riordinarli ancora\n",
    "        # secondo quello scritto in order quindi\n",
    "        items_final = [items_reordered[i] for i in order]\n",
    "        column_reordered = [df_square.columns[i] for i in order]\n",
    "        items_final = dict(zip(column_reordered,items_final))\n",
    "\n",
    "        # df bandizzato\n",
    "        df_square_band = df_square.iloc[order][column_reordered]\n",
    "        # plotto\n",
    "        ax2.spy(df_square_band, marker='.', markersize='1')\n",
    "        #ax2.show()\n",
    "        plt.show()\n",
    "        # banda dataframe inizale\n",
    "        [i, j] = np.where(df_square == 1)\n",
    "        bw = max(i-j) + 1\n",
    "        print(\"Bandwidth first RCM\", bw)\n",
    "\n",
    "        # banda dataframe dopo RCM\n",
    "        [i, j] = np.where(df_square_band == 1)\n",
    "        bw = max(i-j) + 1\n",
    "        print(\"Bandwidth after RCM\", bw)\n",
    "    \n",
    "        return df_square_band, items_final, lista_sensibili\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_conflict(dataframe, row_i, row_j, items_sensibili):\n",
    "    # se hanno un items sensibile in comune allora sono in conflitto\n",
    "    dati_sensibili_row_i = items_sensibili[np.where(dataframe.iloc[row_i][items_sensibili] == 1)]\n",
    "    dati_sensibili_row_j = items_sensibili[np.where(dataframe.iloc[row_j][items_sensibili] == 1)]\n",
    "    # create set\n",
    "    set_j = set(dati_sensibili_row_j)\n",
    "    set_i = set(dati_sensibili_row_i)\n",
    "    # check intersection\n",
    "    return len(set_i.intersection(set_j)) > 0\n",
    "\n",
    "\n",
    "def compute_hist(dataframe, items_sensibili):\n",
    "    hist = dict(dataframe[items_sensibili].sum())\n",
    "    return hist\n",
    "\n",
    "\n",
    "def compute_candidate_list(dataframe, indice_transizione_sensibile, alpha,p, item_sensibili, all_transazioni_sensibili):\n",
    "    alpha_p = alpha * p\n",
    "    lc = list()  # lista candidate\n",
    "    k = 1\n",
    "    # controllo gli alpha*p transazioni precedenti non sono in conflitto\n",
    "    cond = max(indice_transizione_sensibile - alpha_p - k, -1)\n",
    "    i = indice_transizione_sensibile - 1;\n",
    "    while (i > cond):\n",
    "        if check_conflict(dataframe, indice_transizione_sensibile, i, item_sensibili):\n",
    "            k = k + 1\n",
    "        else:\n",
    "            # controllo che nella lista non vi siano gia delle transizioni con quelli item sensibili\n",
    "            # se si non la posso inserire\n",
    "            conflitto_lista = False\n",
    "            for index in lc:\n",
    "                if check_conflict(dataframe, index, i, items_sensibili):\n",
    "                    conflitto_lista = True\n",
    "            if not conflitto_lista:\n",
    "                lc.append(i)\n",
    "            else:\n",
    "                k = k + 1\n",
    "\n",
    "        cond = max(indice_transizione_sensibile - alpha_p - k, -1)\n",
    "        i -= 1\n",
    "        \n",
    "    # alpha*p transizioni successive che non sono in conflitto\n",
    "    k = 1\n",
    "    cond = min(indice_transizione_sensibile + alpha_p + k, len(dataframe))\n",
    "    i = indice_transizione_sensibile + 1\n",
    "    while(i < cond):\n",
    "        if check_conflict(dataframe, indice_transizione_sensibile, i, items_sensibili):\n",
    "            k = k + 1\n",
    "        else:\n",
    "            conflitto_lista = False\n",
    "            for index in lc:\n",
    "                if check_conflict(dataframe, index, i, items_sensibili):\n",
    "                    conflitto_lista = True\n",
    "            if not conflitto_lista:\n",
    "                lc.append(i)\n",
    "            else:\n",
    "                k = k + 1\n",
    "        cond = min(indice_transizione_sensibile + alpha_p + k, len(dataframe))\n",
    "        i += 1\n",
    "    \n",
    "    to_remove = list()\n",
    "    for i in range(0,len(lc)-1):\n",
    "        for j in range(i+1,len(lc)):\n",
    "            if check_conflict(datframe,lc[i],lc[j],items_sensibili):\n",
    "                to_remove.append(lc[j])\n",
    "    to_remove = list(set(to_remove))\n",
    "    for remove in to_remove:\n",
    "        lc.remove(remove)\n",
    "    \n",
    "    error = False\n",
    "    if len(lc) < p:\n",
    "        error = True\n",
    "        \n",
    "    return lc,error\n",
    "\n",
    "\n",
    "def selectBestTransactions(df, candidate_list, transaction_target, p, items_sensibili):\n",
    "    all_items = list(df)\n",
    "    QID_items = [x for x in all_items if x not in items_sensibili]\n",
    "\n",
    "    #lista riportante gli item in comune con transactionTarget\n",
    "    distance = list()    \n",
    "    # remove list che hanno items_sensibili in comune\n",
    "    # bisogna controllare che nella lista candidate non vi siano transizioni in conflitto con loro\n",
    "    \n",
    "    #for id in index[0]:\n",
    "        \n",
    "    for row in candidate_list:\n",
    "        list1 = df.iloc[transaction_target][QID_items]\n",
    "        list2 = df.iloc[row][QID_items]\n",
    "        #da queste due liste, devo escludere le transazioni sensibili.\n",
    "        \n",
    "        #num. elementi in comune di due liste\n",
    "        distance.append(sum([x and y for x, y in zip(list1, list2)]))\n",
    "\n",
    "    #ottengo i p-1 indici della lista candidata con distanza maggiore\n",
    "    major_indexs = list()\n",
    "    for i in range(0, p-1):\n",
    "        max_index,max_value = max(enumerate(distance), key=operator.itemgetter(1))\n",
    "        major_indexs.append(max_index)\n",
    "        distance[max_index] = -1\n",
    "\n",
    "    #seleziono gli indici delle righe del dataframe con maggior QIitems in comune\n",
    "    best_rows = list()\n",
    "    for i in major_indexs:\n",
    "        best_rows.append(candidate_list[i])\n",
    "\n",
    "    return best_rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_grado_privacy(hist_sensible_date, grado_privacy, len_dataframe):\n",
    "    \"\"\"\n",
    "        compute se il grado della privacy può essere soddisfatto, se così non fosse\n",
    "        si diminuisce il grado della privacy per averne uno ottimale, oppure si può\n",
    "        decidere di modificare gli item sensibili\n",
    "    \"\"\"\n",
    "    for value in hist_sensible_date.values():\n",
    "        if value*grado_privacy >=len_dataframe-1:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def get_id_transazioni_sensibili(dataframe_bandizzato, items_sensibili):\n",
    "    \"\"\"\n",
    "        get label delle transazioni sensibili\n",
    "    \"\"\"\n",
    "\n",
    "    transazioni_sensibili = set(list(np.where(dataframe_bandizzato[items_sensibili] == 1)[0]))\n",
    "    transazioni_sensibili_completa = list(np.where(dataframe_bandizzato[items_sensibili] == 1)[0])\n",
    "    # item sensibili della transazione iesime\n",
    "    item_sensibile_per_transazioni = list(np.where(dataframe_bandizzato[items_sensibili] == 1)[1])\n",
    "\n",
    "    return transazioni_sensibili, transazioni_sensibili_completa, item_sensibile_per_transazioni\n",
    "\n",
    "\n",
    "def CAHD(dataframe_bandizzato_temp, items_sensibili, nome_item, grado_privacy = 4, alfa=3):\n",
    "    \"\"\"\n",
    "        funzione per il calcolo di CAHD su un dataframe_bandizzato dopo RCM\n",
    "        con gli items sensibili (vedi paper per teoria)\n",
    "    \"\"\"\n",
    "    # temp per non modificare quello originale\n",
    "    dataframe_bandizzato = dataframe_bandizzato_temp.copy()\n",
    "    #print(len(dataframe_bandizzato))\n",
    "\n",
    "    # calcolo istogramma per i dati sensibili (visto come dizionario)\n",
    "    hist = compute_hist(dataframe_bandizzato, items_sensibili)\n",
    "    soddisfabile = False\n",
    "    # da aggiungere se si vuole modificare la privacy perchè si sa che non viene raggiunta\n",
    "    while not soddisfabile and grado_privacy > 0:\n",
    "        soddisfabile = check_grado_privacy(hist, grado_privacy, len(dataframe_bandizzato))\n",
    "        if not soddisfabile:\n",
    "            grado_privacy -= 1\n",
    "            \n",
    "    print(\"grado di privacy soddisfabile: \", grado_privacy)\n",
    "    # lunghezza del dataframe\n",
    "    remaining = len(dataframe_bandizzato)\n",
    "\n",
    "    # inidice delle righe delle transazioni sensibili non ripetute\n",
    "    # indice delle transizioni sensibili con mapping 1-1 con item_sensibile_per_transizione\n",
    "    # transazioni_sensibili_completa[i] --> indice della transizione\n",
    "    # item_sensibile_per_transazioni[i] --> item sensibile per la transizione sopra\n",
    "    transazioni_sensibili,transazioni_sensibili_completa, item_sensibile_per_transazioni = \\\n",
    "        get_id_transazioni_sensibili(dataframe_bandizzato, items_sensibili)\n",
    "\n",
    "\n",
    "    # riempo il dizionario (hash_map) indicizzata con il numero della riga\n",
    "    for t in transazioni_sensibili:\n",
    "        index_t = np.where(np.array(transazioni_sensibili_completa) == t)[0]\n",
    "\n",
    "    lc = dict()     # lista candidata\n",
    "\n",
    "    #FORMO IL DATAFRAME ANONIMIZZATO [item sensibili sono riportati a destra]\n",
    "    #Nota: codice aggiunto. Molti di questi argomenti possono essere passati esternamente e passati a loro volta\n",
    "    #a funzioni interne\n",
    "    all_items = list(df_square.columns)\n",
    "    QID_items = [x for x in all_items if x not in items_sensibili]\n",
    "    columns_list = QID_items.copy()\n",
    "    for x in items_sensibili:\n",
    "        columns_list.append(x)\n",
    "    # dataframe anonimizzato dopo aver sopostato tutte le colonne degli item sensibili a destra\n",
    "    dataframe_anonimizzato = pd.DataFrame(columns = columns_list,index = df_square.index)\n",
    "    dict_group = list()\n",
    "\n",
    "    #FIX: CAMBIO LA MEMORIZZAZIONE DA NUM.RIGA A LABEL RIGA\n",
    "    # index delle row del datframe bandizzato relativo alle row sensibili\n",
    "    id_sensitive_transaction = dataframe_bandizzato.iloc[list(transazioni_sensibili)].index\n",
    "\n",
    "    #Ciclo finchè ho gruppi da anonimizzare\n",
    "    done = False\n",
    "\n",
    "    # lista dei gruppi con i relativi dati sensibili all'interno\n",
    "    lista_gruppi =list()\n",
    "    sd_gruppi = list()\n",
    "\n",
    "    #indice che cicla tra gli id_delle transazioni sensibili\n",
    "    ts_index = 0\n",
    "    while not done:\n",
    "        #se ho terminato di scorrere la lista delle transazioni sensibili esco dal ciclo\n",
    "        if(ts_index > len(id_sensitive_transaction)-1):\n",
    "            done = True\n",
    "            break\n",
    "        #seleziono la iesima transzione sensibile\n",
    "        q = id_sensitive_transaction[ts_index]\n",
    "        #passo da label a num.di riga\n",
    "        t = dataframe_bandizzato.index.get_loc(q)\n",
    "\n",
    "        #nel caso di cancellazioni, devo aggiornare la lista degli indici delle transazioni sensibili\n",
    "        transazioni_sensibili = list()\n",
    "        for i in id_sensitive_transaction:\n",
    "            transazioni_sensibili.append(dataframe_bandizzato.index.get_loc(i))\n",
    "\n",
    "        #lista candidata LC\n",
    "        lc,errore = compute_candidate_list(dataframe_bandizzato, t, alfa, grado_privacy, items_sensibili, transazioni_sensibili)\n",
    "        # se posso creare il gruppo\n",
    "        if not errore:\n",
    "            group = selectBestTransactions(dataframe_bandizzato, lc, t, grado_privacy,items_sensibili)\n",
    "            #aggiungo la transazione bersaglio\n",
    "            group.append(t)\n",
    "\n",
    "            # somma degli items sensibili del gruppo iesimo relativo\n",
    "            selected_sensitive_items = dataframe_bandizzato.iloc[group][items_sensibili].sum()\n",
    "            # temp hist\n",
    "            temp_hist = hist.copy()\n",
    "            # aggiorno le occorrenze di ogni item sensbile\n",
    "\n",
    "            for index in selected_sensitive_items.index:\n",
    "                temp_hist[index] -= selected_sensitive_items.loc[index]\n",
    "\n",
    "            # controllo se il gruppo creato va bene\n",
    "            found = False\n",
    "            for index in temp_hist.keys():\n",
    "                # se non si può più soddisfare il grado di privacy\n",
    "\n",
    "                if temp_hist[index] * grado_privacy > remaining:\n",
    "                    found = True\n",
    "                    ts_index += 1\n",
    "                    break\n",
    "\n",
    "            # se il gruppo invece va bene\n",
    "            if not found:\n",
    "                # update hist\n",
    "                hist = temp_hist.copy()\n",
    "                #DEVO RIMUOVERE EVENTUALI TRANSAZIONI SENSIBILI COMPRESE NEL GRUPPO DA id_sensitive_transaction\n",
    "                label_group = dataframe_bandizzato.iloc[group].index\n",
    "                id_sensitive_transaction = [x for x in id_sensitive_transaction if x not in label_group]\n",
    "\n",
    "                # indice iesimo -> indice delle transazioni del gruppo iesimo\n",
    "                dict_group.append(dataframe_bandizzato.index[group])\n",
    "\n",
    "                # metto i QID nel datframe anonimizzato\n",
    "                dataframe_anonimizzato.loc[list(dataframe_bandizzato.index[group])] = dataframe_bandizzato.loc[list(dataframe_bandizzato.index[group])]\n",
    "\n",
    "                lista_gruppi.append(dataframe_bandizzato.loc[list(dataframe_bandizzato.index[group]),QID_items])\n",
    "\n",
    "                for index in list(dataframe_bandizzato.index[group]):\n",
    "                    # metto la somma dei SD del gruppo per ogni row del gruppo\n",
    "                    dataframe_anonimizzato.loc[index][selected_sensitive_items.index] = selected_sensitive_items\n",
    "\n",
    "                sd_gruppi.append(selected_sensitive_items) # aggiungo somma item sensibili relativi al gruppo iesimo\n",
    "\n",
    "                # le droppo dal df iniziale\n",
    "                dataframe_bandizzato = dataframe_bandizzato.drop(list(dataframe_bandizzato.index[group]))\n",
    "\n",
    "                # compute row rimanenti\n",
    "                remaining = len(dataframe_bandizzato.index)\n",
    "\n",
    "        else:\n",
    "            ts_index += 1\n",
    "\n",
    "    #terminato il ciclo di formazione dei gruppi, mi rimane un supergruppo con le transazioni sensibili rimanenti o meno.\n",
    "\n",
    "    # somma item sensibili nel gruppo rimasto\n",
    "    #for i in range(0,dataframe_bandizzato.shape[0]):\n",
    "    #    transaction = dataframe_bandizzato.index[i]\n",
    "    #    dataframe_anonimizzato.loc[transaction] = dataframe_bandizzato.iloc[i]\n",
    "\n",
    "    # update del dataframe anonimizzato con il super gruppo finale\n",
    "    selected_sensitive_items = dataframe_bandizzato[items_sensibili].sum()\n",
    "    dataframe_anonimizzato.loc[dataframe_bandizzato.index] = dataframe_bandizzato\n",
    "    # metto la somma degli item\n",
    "    for index in list(dataframe_bandizzato.index):\n",
    "        dataframe_anonimizzato.loc[index,items_sensibili]= selected_sensitive_items\n",
    "    lista_gruppi.append(dataframe_bandizzato[QID_items])\n",
    "    sd_gruppi.append(selected_sensitive_items)\n",
    "    # del datframe iniziale\n",
    "    dataframe_bandizzato = None\n",
    "\n",
    "    return dataframe_anonimizzato,lista_gruppi, sd_gruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-197adbfebb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_square\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems_sensibili\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_band_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_finale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnome_file_item\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Dataset Paper/lista_items_BMS1.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_sensibile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-2658234ade93>\u001b[0m in \u001b[0;36mcompute_band_matrix\u001b[0;34m(original_dataset, dim_finale, nome_file_item, num_sensibile)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mzero_data_to_add\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[1;31m# aggiungo li zero con la dimensione finale relativa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[1;31m#zero_data_to_add.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_square,items,items_sensibili = compute_band_matrix(original_dataset = df, dim_finale = 500, nome_file_item=\"Dataset Paper/lista_items_BMS1.txt\",num_sensibile=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{27: '12 PENCILS TALL TUBE SKULLS',\n",
       " 114: '60 TEATIME FAIRY CAKE CASES',\n",
       " 215: 'ANTIQUE MID BLUE FLOWER EARRINGS',\n",
       " 233: 'ASS COL CIRCLE MOBILE ',\n",
       " 369: 'BISCUIT TIN VINTAGE CHRISTMAS',\n",
       " 407: 'BLACK LOVE BIRD CANDLE',\n",
       " 459: 'BLUE DELPHINIUM ARTIFICIAL FLOWER',\n",
       " 491: 'BLUE MURANO TWIST BRACELET',\n",
       " 522: 'BLUE POT PLANT CANDLE ',\n",
       " 660: 'CARD CAT AND TREE ',\n",
       " 797: 'CHRISTMAS HANGING TREE WITH BELL',\n",
       " 928: 'CROCHET BEAR RED/BLUE  KEYRING',\n",
       " 1108: 'DRAWER KNOB CRACKLE GLAZE GREEN',\n",
       " 1182: 'ELEPHANT BIRTHDAY CARD ',\n",
       " 1216: 'ENAMEL MUG PANTRY',\n",
       " 1236: 'ETCHED GLASS COASTER',\n",
       " 1335: 'FLOWER GLASS GARLAND NECKL.36\"BLUE',\n",
       " 1341: 'FLOWER SHOP DESIGN MUG',\n",
       " 1356: 'FOLDING MIRROR RED  ',\n",
       " 1363: 'FOLDING UMBRELLA WHITE/RED POLKADOT',\n",
       " 1373: 'FOLKART ZINC STAR CHRISTMAS DEC',\n",
       " 1640: 'HAND OPEN SHAPE DECO.WHITE',\n",
       " 1669: 'HANGING HEART WITH BELL',\n",
       " 1688: 'HAPPY BIRTHDAY CARD STRIPEY TEDDY',\n",
       " 1736: 'HERB MARKER CHIVES ',\n",
       " 1746: 'HOME BUILDING BLOCK WORD',\n",
       " 1830: 'JAM JAR WITH GREEN LID',\n",
       " 1893: 'KEY RING BASEBALL BOOT ASSORTED ',\n",
       " 1968: 'LARGE ZINC GLASS CANDLEHOLDER',\n",
       " 2207: 'MONEY BOX FIRST ADE DESIGN',\n",
       " 2293: 'NUMBER TILE VINTAGE FONT 3',\n",
       " 2507: 'PENNY FARTHING BIRTHDAY CARD',\n",
       " 2619: 'PINK HEART DOTS HOT WATER BOTTLE',\n",
       " 2768: 'PSYCHEDELIC WALL THERMOMETER',\n",
       " 2783: 'PURPLE FRANGIPANI HAIRCLIP',\n",
       " 2835: 'RED DAISY POCKET BOOK ',\n",
       " 3200: 'SET OF 3 HANGING OWLS OLLIE BEAK',\n",
       " 3208: 'SET OF 3 WOODEN SLEIGH DECORATIONS',\n",
       " 3332: 'SET/5 RED SPOTTY LID GLASS BOWLS',\n",
       " 3437: 'SMALL BLUE PROVENCAL CERAMIC BALL',\n",
       " 3577: 'SUNSET CHECK HAMMOCK',\n",
       " 3608: 'T-LIGHT HOLDER SILVER HEART HANDLE',\n",
       " 3815: 'VINTAGE RED ENAMEL TRIM JUG ',\n",
       " 3822: 'VINTAGE ROSE BEAD BRACELET BLACK',\n",
       " 3830: 'VINTAGE UNION JACK CUSHION COVER',\n",
       " 4031: 'WRAP COWBOYS  ',\n",
       " 4125: 'damaged stock',\n",
       " 4175: 'rusty thrown away',\n",
       " 4184: 'sold as set on dotcom and amazon',\n",
       " 4188: 'stock check'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grado di privacy soddisfabile:  4\n"
     ]
    }
   ],
   "source": [
    "dataframe_anonimizzato,list_gruppi, sd_gruppi = CAHD(df_square,items_sensibili,[],grado_privacy=4,alfa = 3)\n",
    "#dataframe_anonimizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[407     1\n",
       " 2207    0\n",
       " 459     0\n",
       " 3608    0\n",
       " dtype: int64, 407     1\n",
       " 2207    0\n",
       " 459     0\n",
       " 3608    0\n",
       " dtype: int64, 407     0\n",
       " 2207    0\n",
       " 459     0\n",
       " 3608    0\n",
       " dtype: int64]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_gruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      2835  1108  1669  1736  1335  3822  1640  1830  369   27    ...   1216  \\\n",
       " 1179     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1396     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       " 2678     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2686     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " \n",
       "       233   928   2619  3437  4175  797   4188  1236  1688  \n",
       " 1179     0     0     0     0     0     0     0     0     0  \n",
       " 1396     0     0     0     0     0     0     0     0     0  \n",
       " 2678     0     0     0     0     0     0     0     0     0  \n",
       " 2686     0     0     0     0     0     0     0     0     0  \n",
       " \n",
       " [4 rows x 46 columns],\n",
       "       2835  1108  1669  1736  1335  3822  1640  1830  369   27    ...   1216  \\\n",
       " 1213     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1278     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3968     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3979     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " \n",
       "       233   928   2619  3437  4175  797   4188  1236  1688  \n",
       " 1213     0     0     0     0     0     0     0     0     0  \n",
       " 1278     0     0     0     0     0     0     0     0     0  \n",
       " 3968     0     0     0     0     0     0     0     0     0  \n",
       " 3979     0     0     0     0     0     0     0     0     0  \n",
       " \n",
       " [4 rows x 46 columns],\n",
       "       2835  1108  1669  1736  1335  3822  1640  1830  369   27    ...   1216  \\\n",
       " 628      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1282     1     0     1     0     0     0     0     0     0     0  ...      0   \n",
       " 2090     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3317     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2935     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3101     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3772     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1638     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2912     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 4188     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2491     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2555     0     0     0     0     0     0     0     1     0     0  ...      0   \n",
       " 3899     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3399     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1976     0     0     0     0     0     0     0     0     1     1  ...      0   \n",
       " 2997     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3413     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 916      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2597     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3987     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 668      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3581     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2457     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1460     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 226      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1082     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1030     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 552      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 48       0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3335     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1823     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 961      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2359     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 985      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2233     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2141     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2958     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 3187     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 104      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 2190     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 1386     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " 810      0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       " \n",
       "       233   928   2619  3437  4175  797   4188  1236  1688  \n",
       " 628      0     0     0     0     0     0     0     0     0  \n",
       " 1282     0     0     0     0     0     0     0     0     0  \n",
       " 2090     0     0     0     0     0     0     0     0     0  \n",
       " 3317     0     0     0     0     0     0     0     0     0  \n",
       " 2935     0     0     0     0     0     0     0     0     0  \n",
       " 3101     0     0     0     0     0     0     0     0     0  \n",
       " 3772     0     0     0     0     0     0     0     0     0  \n",
       " 1638     0     0     0     0     0     0     0     0     0  \n",
       " 2912     0     0     0     0     0     0     0     0     0  \n",
       " 4188     0     0     0     0     0     0     0     0     0  \n",
       " 2491     0     0     0     0     0     0     0     0     0  \n",
       " 2555     0     0     0     0     0     0     0     0     0  \n",
       " 3899     0     0     0     0     0     0     0     0     0  \n",
       " 3399     0     0     0     0     0     0     0     0     0  \n",
       " 1976     0     0     0     0     0     0     0     0     0  \n",
       " 2997     0     0     0     0     0     0     0     0     0  \n",
       " 3413     0     0     0     0     0     0     0     0     0  \n",
       " 916      0     0     0     0     0     0     0     0     0  \n",
       " 2597     0     0     0     0     0     0     0     0     0  \n",
       " 3987     0     0     0     0     0     0     0     0     0  \n",
       " 668      0     0     0     0     0     0     0     0     0  \n",
       " 3581     0     0     0     0     0     0     0     0     0  \n",
       " 2457     0     0     0     0     0     0     0     0     0  \n",
       " 1460     0     0     0     0     0     0     0     0     0  \n",
       " 226      0     0     0     0     0     0     0     0     0  \n",
       " 1082     0     0     0     0     0     0     0     0     0  \n",
       " 1030     0     0     0     0     0     0     0     0     0  \n",
       " 552      0     0     0     0     0     0     0     0     0  \n",
       " 48       0     0     0     0     0     0     0     0     0  \n",
       " 3335     0     0     0     0     0     0     0     0     0  \n",
       " 1823     0     0     0     0     0     0     0     0     0  \n",
       " 961      0     0     0     0     0     0     0     0     0  \n",
       " 2359     0     0     0     0     0     0     0     0     0  \n",
       " 985      0     0     0     0     0     0     0     0     0  \n",
       " 2233     0     0     0     0     0     0     0     0     0  \n",
       " 2141     0     0     0     0     0     0     0     0     0  \n",
       " 2958     0     0     0     0     0     0     0     0     0  \n",
       " 3187     0     0     0     0     0     0     0     0     0  \n",
       " 104      0     0     0     0     0     0     0     0     0  \n",
       " 2190     0     0     0     0     0     0     0     0     0  \n",
       " 1386     0     0     0     0     0     0     0     0     0  \n",
       " 810      0     0     0     0     0     0     0     0     0  \n",
       " \n",
       " [42 rows x 46 columns]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4188</th>\n",
       "      <th>1746</th>\n",
       "      <th>4031</th>\n",
       "      <th>369</th>\n",
       "      <th>2507</th>\n",
       "      <th>1236</th>\n",
       "      <th>407</th>\n",
       "      <th>2207</th>\n",
       "      <th>459</th>\n",
       "      <th>3608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      4188  1746  4031  369   2507  1236  407   2207  459   3608\n",
       "2997     0     0     0     0     0     0     0     0     0     0\n",
       "1213     0     0     0     0     0     0     0     0     0     0\n",
       "3979     0     0     0     0     0     0     1     0     0     0\n",
       "3987     0     0     1     0     0     0     0     0     0     0\n",
       "3581     0     0     1     0     0     0     0     0     0     0\n",
       "3899     0     1     0     0     0     0     0     0     0     0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_square.loc[[2997, 1213, 3979, 3987, 3581, 3899]][items_sensibili]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
